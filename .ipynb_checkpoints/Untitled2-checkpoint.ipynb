{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6536006-ee95-4c0f-b1b9-870011396a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping de valores factorized:\n",
      "{0: 'INTELECTUAL', 1: 'AUDITIVA ', 2: 'FISICA', 3: 'INTELECTUAL ', 4: 'Sin Discapacidad', 5: 'PSICOSOCIAL', 6: 'VISUAL', 7: 'AUTISMO', 8: 'MIXTA'}\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 165 entries, 0 to 164\n",
      "Data columns (total 4 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   TIPO DE DISCAPACIDAD   165 non-null    object \n",
      " 1   EDAD AÑOS/MESES        165 non-null    float64\n",
      " 2   PORCENTAJE\n",
      "%           165 non-null    object \n",
      " 3   ASISTENCIA \n",
      "SI/NO      165 non-null    object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 5.3+ KB\n",
      "Distribución en el conjunto completo: ASISTENCIA \\nSI/NO\n",
      "SI    128\n",
      "NO     37\n",
      "Name: count, dtype: int64\n",
      "Distribución en el conjunto de entrenamiento: ASISTENCIA \\nSI/NO\n",
      "SI    89\n",
      "NO    26\n",
      "Name: count, dtype: int64\n",
      "Distribución en el conjunto de prueba: ASISTENCIA \\nSI/NO\n",
      "SI    39\n",
      "NO    11\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "Confusion Matrix:\n",
      "[[11  0]\n",
      " [ 0 39]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# Cargar el archivo Excel desde la ruta especificada\n",
    "file_path = 'C:/Users/D4/Documents/Maestría/Vinculacion/BD_Discapacidades.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Seleccionar solo las columnas relevantes\n",
    "columns_to_use = ['TIPO DE DISCAPACIDAD ', 'EDAD AÑOS/MESES', 'PORCENTAJE\\n%', 'ASISTENCIA \\nSI/NO']\n",
    "data_cleaned = data[columns_to_use].copy()\n",
    "\n",
    "data_cleaned['TIPO DE DISCAPACIDAD '] = data_cleaned['TIPO DE DISCAPACIDAD '].fillna('Sin Discapacidad')\n",
    "data_cleaned['PORCENTAJE\\n%'] = data_cleaned['PORCENTAJE\\n%'].fillna('0%')\n",
    "data_cleaned['PORCENTAJE\\n%'] = data_cleaned['PORCENTAJE\\n%'].replace('NO APLICA', '0%')\n",
    "\n",
    "# Factorizar la columna 'TIPO DE DISCAPACIDAD '\n",
    "factorized_values, unique_labels = pd.factorize(data_cleaned['TIPO DE DISCAPACIDAD '])\n",
    "\n",
    "# Mostrar los valores únicos y su correspondencia con los números factorized\n",
    "label_mapping = dict(enumerate(unique_labels))\n",
    "print(\"Mapping de valores factorized:\")\n",
    "print(label_mapping)\n",
    "\n",
    "# Convertir la columna 'TIPO DE DISCAPACIDAD ' a valores numéricos mediante codificación\n",
    "data_cleaned.loc[:, 'TIPO DE DISCAPACIDAD '] = pd.factorize(data_cleaned['TIPO DE DISCAPACIDAD '])[0]\n",
    "\n",
    "# Convertir valores no numéricos en la columna \"PORCENTAJE\\n%\" a NaN\n",
    "data_cleaned.loc[:, 'PORCENTAJE\\n%'] = pd.to_numeric(data_cleaned['PORCENTAJE\\n%'], errors='coerce')\n",
    "\n",
    "# Manejar valores faltantes\n",
    "data_cleaned.loc[:, 'TIPO DE DISCAPACIDAD '] = data_cleaned['TIPO DE DISCAPACIDAD '].fillna(data_cleaned['TIPO DE DISCAPACIDAD '].mode()[0])\n",
    "data_cleaned.loc[:, 'EDAD AÑOS/MESES'] = data_cleaned['EDAD AÑOS/MESES'].fillna(data_cleaned['EDAD AÑOS/MESES'].median())\n",
    "data_cleaned.loc[:, 'PORCENTAJE\\n%'] = data_cleaned['PORCENTAJE\\n%'].fillna(data_cleaned['PORCENTAJE\\n%'].median())\n",
    "\n",
    "# Verificar que todas las columnas sean numéricas\n",
    "data_cleaned.info()\n",
    "\n",
    "# Verificar la distribución de la columna objetivo en el conjunto de datos completo\n",
    "distribution_full = data_cleaned['ASISTENCIA \\nSI/NO'].value_counts()\n",
    "print(\"Distribución en el conjunto completo:\", distribution_full)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba con estratificación\n",
    "X = data_cleaned.drop(columns=['ASISTENCIA \\nSI/NO'])\n",
    "y = data_cleaned['ASISTENCIA \\nSI/NO']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Verificar la distribución de la columna objetivo en los conjuntos de entrenamiento y prueba\n",
    "distribution_train = y_train.value_counts()\n",
    "distribution_test = y_test.value_counts()\n",
    "\n",
    "print(\"Distribución en el conjunto de entrenamiento:\", distribution_train)\n",
    "print(\"Distribución en el conjunto de prueba:\", distribution_test)\n",
    "\n",
    "# Si los datos son adecuados, entrenar el modelo de Random Forest\n",
    "if len(distribution_full) > 1 and len(distribution_train) > 1 and len(distribution_test) > 1:\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Guardar el modelo entrenado\n",
    "    joblib.dump(model, 'modelo_entrenado.pkl')\n",
    "\n",
    "    # Realizar predicciones\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluar el rendimiento del modelo\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro', zero_division=1)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "else:\n",
    "    print(\"No hay suficientes datos de ambas clases para entrenar el modelo.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2639abb5-087e-4cd1-9a87-12d38fbe1258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      1\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "160    0\n",
      "161    2\n",
      "162    2\n",
      "163    0\n",
      "164    5\n",
      "Name: TIPO DE DISCAPACIDAD , Length: 165, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data_cleaned['TIPO DE DISCAPACIDAD '])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
